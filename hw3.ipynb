{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 158 HW3\n",
    "## Christina Leung, A15468909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "import scipy.optimize\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    try:\n",
    "      g = d['gameID']\n",
    "    except Exception as e:\n",
    "      g = None\n",
    "    yield u,g,d\n",
    "\n",
    "pairs_train = []\n",
    "pairs_valid = []\n",
    "games = set([])\n",
    "\n",
    "i = 0\n",
    "for user,game,d in readJSON(\"train.json.gz\"):\n",
    "  if i < 165000:\n",
    "    pairs_train.append([user, game, True])\n",
    "  else:\n",
    "    pairs_valid.append([user, game, True])\n",
    "  i += 1\n",
    "  games.add(game)\n",
    "games = list(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1\n",
    "print(len(pairs_valid))\n",
    "for pair in pairs_valid:\n",
    "    if pair[2] is False:\n",
    "        continue\n",
    "    user = pair[0]\n",
    "    while True:\n",
    "        game = random.choice(games)\n",
    "        if (user, game, True) not in pairs_valid and (user, game, True) not in pairs_train:\n",
    "            if (user, game, False) not in pairs_valid:\n",
    "                pairs_valid.append((user, game, False))\n",
    "                break\n",
    "print(len(pairs_valid))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "4979\n",
      "accuracy:\n",
      "0.6782\n"
     ]
    }
   ],
   "source": [
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "\n",
    "for pair in pairs_train:\n",
    "    gameCount[pair[1]] += 1\n",
    "    totalPlayed += 1\n",
    "\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPlayed/2: break\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "falsepos = 0\n",
    "falseneg = 0\n",
    "for pair in pairs_valid:\n",
    "  total += 1\n",
    "  g = pair[1]\n",
    "  ans = pair[2]\n",
    "  guess = False\n",
    "  if g in return1:\n",
    "    guess = True\n",
    "  if guess == ans:\n",
    "    correct += 1\n",
    "  if guess == True and ans == False:\n",
    "    falsepos +=1\n",
    "  if guess == False and ans == True:\n",
    "    falseneg += 1\n",
    "print(falsepos)\n",
    "print(falseneg)\n",
    "print('accuracy:')\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "Accuracy: 0.6791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2659\n",
      "3340\n",
      "accuracy:\n",
      "0.70005\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 2\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPlayed/1.5: break\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "falsepos = 0\n",
    "falseneg = 0\n",
    "for pair in pairs_valid:\n",
    "  total += 1\n",
    "  g = pair[1]\n",
    "  ans = pair[2]\n",
    "  guess = False\n",
    "  if g in return1:\n",
    "    guess = True\n",
    "  if guess == ans:\n",
    "    correct += 1\n",
    "  if guess == True and ans == False:\n",
    "    falsepos +=1\n",
    "  if guess == False and ans == True:\n",
    "    falseneg += 1\n",
    "print(falsepos)\n",
    "print(falseneg)\n",
    "print('accuracy:')\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "Uses the top 66.67%, accuracy of 0.69745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 3\n",
    "user2game = {}\n",
    "game2user = {}\n",
    "for pair in pairs_train:\n",
    "    user = pair[0]\n",
    "    game = pair[1]\n",
    "    if game in game2user and user not in game2user[game]:\n",
    "        game2user[game].add(user)\n",
    "    else:\n",
    "        game2user[game] = set([user])\n",
    "    if user in user2game and game not in user2game[user]:\n",
    "        user2game[user].add(game)\n",
    "    else :\n",
    "        user2game[user] = set([game])\n",
    "def Jaccard(u, g):\n",
    "    usergames = user2game[u]\n",
    "    scores = []\n",
    "    s1 = game2user[g]\n",
    "    for x in usergames:\n",
    "        s2 = game2user[x]\n",
    "        numer = len(s1.intersection(s2))\n",
    "        denom = len(s1.union(s2))\n",
    "        scores.append(numer/denom)\n",
    "    if (len(scores) > 0):\n",
    "        return max(scores)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3107\n",
      "3478\n",
      "accuracy:\n",
      "0.67075\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "falsepos = 0\n",
    "falseneg = 0\n",
    "for pair in pairs_valid:\n",
    "    real = pair[2]\n",
    "    guess = Jaccard(pair[0], pair[1])\n",
    "    if (guess > 0.031):\n",
    "        guess = True\n",
    "    else:\n",
    "        guess = False\n",
    "    if guess == real:\n",
    "        correct += 1\n",
    "    if guess == True and real == False:\n",
    "        falsepos +=1\n",
    "    if guess == False and real == True:\n",
    "        falseneg += 1\n",
    "print(falsepos)\n",
    "print(falseneg)\n",
    "print('accuracy:')\n",
    "print(correct/len(pairs_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Selected threshold is 0.031 because it yielded the maximum accuracy in the trials. Going higher or lower than that number in increments of 0.001 did not improve the accuracy.<br>\n",
    "Different Threshold Trials:<br>\n",
    "Threshold: 0.029, Accuracy: 0.6669<br>\n",
    "Threshold: 0.030, Accuracy: 0.66775<br>\n",
    "Threshold: 0.031, Accuracy: 0.6692<br>\n",
    "Threshold: 0.032, Accuracy: 0.6686<br>\n",
    "Threshold: 0.033, Accuracy: 0.666<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993\n",
      "3020\n",
      "accuracy:\n",
      "0.69935\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 4\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPlayed/1.5: break\n",
    "def JaccardPop(u, g):\n",
    "    usergames = set([])\n",
    "    if u in user2game:\n",
    "        usergames = user2game[u]\n",
    "    scores = []\n",
    "    s1 = set([])\n",
    "    if g in game2user:\n",
    "        s1 = game2user[g]\n",
    "    for x in usergames:\n",
    "        s2 = set([])\n",
    "        if x in game2user:\n",
    "            s2 = game2user[x]\n",
    "        numer = len(s1.intersection(s2))\n",
    "        denom = len(s1.union(s2))\n",
    "        scores.append(numer/denom)\n",
    "    jac = 0\n",
    "    if (len(scores) > 0):\n",
    "        jac = max(scores)\n",
    "    if g in return1:\n",
    "        jac += 0.015\n",
    "    else:\n",
    "        jac -= 0.007\n",
    "    if jac > 0.035:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "correct = 0\n",
    "total = 0\n",
    "falsepos = 0\n",
    "falseneg = 0\n",
    "for pair in pairs_valid:\n",
    "    total += 1\n",
    "    real = pair[2]\n",
    "    guess = JaccardPop(pair[0], pair[1])\n",
    "    if guess == real:\n",
    "        correct += 1\n",
    "    if guess == True and real == False:\n",
    "        falsepos +=1\n",
    "    if guess == False and real == True:\n",
    "        falseneg += 1\n",
    "print(falsepos)\n",
    "print(falseneg)\n",
    "print('accuracy:')\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Accuracy: 0.6992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 5\n",
    "predictions = open(\"predictions_Played.txt\", 'w')\n",
    "for l in open(\"pairs_Played.txt\"):\n",
    "  if l.startswith(\"userID\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,g = l.strip().split('-')\n",
    "  if JaccardPop(u, g) == True:\n",
    "    predictions.write(u + '-' + g + \",1\\n\")\n",
    "  else:\n",
    "    predictions.write(u + '-' + g + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "user name: christinaleung123<br>\n",
    "Kaggle Accuracy: 0.71040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 6\n",
    "def readCatJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    r = d['text']\n",
    "    try:\n",
    "      g = d['genreID']\n",
    "    except Exception as e:\n",
    "      g = None\n",
    "    yield r,g,d\n",
    "    \n",
    "catDict = {\n",
    "  \"Action\": 0,\n",
    "  \"Strategy\": 1,\n",
    "  \"RPG\": 2,\n",
    "  \"Adventure\": 3,\n",
    "  \"Sport\": 4\n",
    "}\n",
    "\n",
    "cat_train = []\n",
    "cat_valid = []\n",
    "i = 0\n",
    "for r,g,d in readCatJSON(\"train_Category.json.gz\"):\n",
    "    if i < 165000:\n",
    "        cat_train.append((r, g))\n",
    "    else:\n",
    "        cat_valid.append((r, g))\n",
    "    i += 1\n",
    "print(len(cat_train))\n",
    "print(len(cat_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(544597, 'the'), (317620, 'and'), (305414, 'a'), (291882, 'to'), (245359, 'game'), (227234, 'of'), (208417, 'is'), (200633, 'you'), (195953, 'i'), (190966, 'it')]\n"
     ]
    }
   ],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in cat_train:\n",
    "  r = ''.join([c for c in d[0].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words2 = [x for x in counts[:10]]\n",
    "print(words2)\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "format is (count, word)<br>\n",
    "[(544597, 'the'), (317620, 'and'), (305414, 'a'), (291882, 'to'), (245359, 'game'), (227234, 'of'), (208417, 'is'), (200633, 'you'), (195953, 'i'), (190966, 'it')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=10000, multi_class='auto', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION 7\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X = [feature(d[0]) for d in cat_train]\n",
    "y = [d[1] for d in cat_train]\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced', max_iter=10000) # Fit classifier\n",
    "mod.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.6271\n"
     ]
    }
   ],
   "source": [
    "X_val = [feature(d[0]) for d in cat_valid]\n",
    "y_val = [d[1] for d in cat_valid]\n",
    "pred = mod.predict(X_val)\n",
    "TP_ = numpy.logical_and(pred, y_val) # Calculate accuracy\n",
    "TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(y_val))\n",
    "TP = sum(TP_)\n",
    "TN = sum(TN_)\n",
    "print('accuracy:')\n",
    "print((TP + TN) / len(cat_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Accuracy: 0.6269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "stops = stopwords.words('english')\n",
    "for d in cat_train:\n",
    "  r = ''.join([c for c in d[0].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    w = stemmer.stem(w)\n",
    "    if w not in stops:\n",
    "        wordCount[w] += 1\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=10000, multi_class='auto', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION 8  \n",
    "words = [x[1] for x in counts[:5000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "def feature2(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X = [feature2(d[0]) for d in cat_train]\n",
    "X = scipy.sparse.lil_matrix(X)\n",
    "y = [d[1] for d in cat_train]\n",
    "mod = linear_model.LogisticRegression(C=1.0E-3, class_weight='balanced', max_iter = 10000) # Fit classifier\n",
    "#mod = linear_model.Ridge(1.0E5, fit_intercept=False)\n",
    "mod.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6833\n"
     ]
    }
   ],
   "source": [
    "X_val = [feature2(d[0]) for d in cat_valid]\n",
    "X_val = scipy.sparse.lil_matrix(X_val)\n",
    "y_val = [d[1] for d in cat_valid]\n",
    "pred = mod.predict(X_val)\n",
    "TP_ = numpy.logical_and(pred, y_val) # Calculate accuracy\n",
    "TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(y_val))\n",
    "TP = sum(TP_)\n",
    "TN = sum(TN_)\n",
    "print((TP + TN) / len(cat_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON2(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    try:\n",
    "      g = d['gameID']\n",
    "    except Exception as e:\n",
    "      g = None\n",
    "    yield u,g,d\n",
    "X_test = []\n",
    "for u,_,d in readJSON2(\"test_Category.json.gz\"):\n",
    "    X_test.append(d['text'])\n",
    "X_test = [feature2(d) for d in X_test]\n",
    "pred = mod.predict(X_test)\n",
    "i = 0\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"userID-reviewID,prediction\\n\")\n",
    "for u,_,d in readJSON2(\"test_Category.json.gz\"):\n",
    "  cat = pred[i]\n",
    "  i += 1\n",
    "  predictions.write(u + '-' + d['reviewID'] + \",\" + str(cat) + \"\\n\")\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 8\n",
    "Used stemming and removed stopwords<Br>\n",
    "    \n",
    "Using dictionary size of 500:<br>\n",
    "C = 1.0, accuracy = 0.6076<br>\n",
    "C = 1.0E-5, accuracy = 0.5092<br>\n",
    "C = 1.0E-4, accuracy = 0.5735<br>\n",
    "C = 1.0E-3, accuracy = 0.606<br>\n",
    "\n",
    "Using dictionary size of 1000:<br>\n",
    "C = 1.0, accuracy = 0.6458<br>\n",
    "C = 1.0E-5, accuracy = 0.5164<br>\n",
    "C = 1.0E-4, accuracy = 0.5946<br>\n",
    "C = 1.0E-3, accuracy = 0.6336<br>\n",
    "\n",
    "Using dictionary size of 5000:<br>\n",
    "C = 1.0, accuracy = 0.7286<br>\n",
    "C = 1.0E-3, accuracy = 0.6833<br>\n",
    "C = 1.0E-2, accuracy = 0.7257<br>\n",
    "C = 1.0E-1, accuracy = 0.7293<br>\n",
    "\n",
    "Best performance using dictionary size of 5000, C = 1.0E-1, Accuracy = 0.7293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
