{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE 158 HW4\n",
    "### Christina Leung, A15468909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from nltk.corpus import stopwords\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from collections import Counter \n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "data = []\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstten = []\n",
    "for i in range(0, 10000):\n",
    "    firstten.append(data[i]['text'].translate(str.maketrans('', '', string.punctuation)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4092, ('this', 'game')), (3867, ('the', 'game')), (3355, ('of', 'the')), (1988, ('in', 'the')), (1910, ('game', 'is'))]\n",
      "266396\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1\n",
    "counts = defaultdict(int)\n",
    "for l in firstten:\n",
    "    b = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "grams = [x for x in counts[:5]]\n",
    "print(grams)\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "There are 266396 unique bigrams. The five most popular ones are (format is (count, bigram):<br>\n",
    "[(4092, ('this', 'game')), (3867, ('the', 'game')), (3355, ('of', 'the')), (1988, ('in', 'the')), (1910, ('game', 'is'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 2\n",
    "corpus = [x[1] for x in counts[:1000]]\n",
    "gramId = dict(zip(corpus, range(len(corpus))))\n",
    "gramSet = set(corpus)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(gramSet)\n",
    "    l = datum\n",
    "    r = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for w in r:\n",
    "        if w in gramSet:\n",
    "            feat[gramId[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "def res(datum):\n",
    "    return math.log(datum['hours'] + 1, 2)\n",
    "    \n",
    "X = [feature(d) for d in firstten]\n",
    "y = [res(d) for d in data[0:10000]]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.409616426571927\n"
     ]
    }
   ],
   "source": [
    "est = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(est, y)).mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "MSE = 4.409616426571927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 3\n",
    "counts = defaultdict(int)\n",
    "for l in firstten:\n",
    "    b = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "    b = l.split(\" \")\n",
    "    for val in b:\n",
    "        counts[(val, '')] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [x[1] for x in counts[:1000]]\n",
    "gramId = dict(zip(corpus, range(len(corpus))))\n",
    "gramSet = set(corpus)\n",
    "def feature2(datum):\n",
    "    feat = [0]*len(gramSet)\n",
    "    l = datum\n",
    "    r = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for w in r:\n",
    "        if w in gramSet:\n",
    "            feat[gramId[w]] += 1\n",
    "    r = l.split(\" \")\n",
    "    for w in r:\n",
    "        if (w,'') in gramSet:\n",
    "            feat[gramId[(w,'')]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X2 = [feature2(d) for d in firstten]\n",
    "y2 = [res(d) for d in data[0:10000]]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2428508756634855\n"
     ]
    }
   ],
   "source": [
    "est = clf.predict(X2)\n",
    "mse = numpy.square(numpy.subtract(est, y2)).mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "MSE = 4.2428508756634855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 4\n",
    "df = defaultdict(int)\n",
    "unigrams = defaultdict(int)\n",
    "for d in firstten:\n",
    "    curr = set([])\n",
    "    tokens = d.split()\n",
    "    for w in tokens:\n",
    "        unigrams[w] += 1\n",
    "        if w not in curr:\n",
    "            curr.add(w)\n",
    "            df[w] += 1\n",
    "ugrams = [(unigrams[w], w) for w in unigrams]\n",
    "ugrams.sort()\n",
    "ugrams.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Document Frequencies:\n",
      "destiny:\n",
      "3.3010299956639813\n",
      "annoying:\n",
      "1.8356471442155629\n",
      "likeable\n",
      "3.0457574905606752\n",
      "chapter\n",
      "2.214670164989233\n",
      "interesting\n",
      "1.3575354797578787\n"
     ]
    }
   ],
   "source": [
    "print('Inverse Document Frequencies:')\n",
    "tmp1 = math.log10(len(firstten)/(1 + df['destiny']))\n",
    "print('destiny:')\n",
    "print(tmp1)\n",
    "tmp2 = math.log10(len(firstten)/(1 + df['annoying']))\n",
    "print('annoying:')\n",
    "print(tmp2)\n",
    "tmp3 = math.log10(len(firstten)/(1 + df['likeable']))\n",
    "print('likeable')\n",
    "print(tmp3)\n",
    "tmp4 = math.log10(len(firstten)/(1 + df['chapter']))\n",
    "print('chapter')\n",
    "print(tmp4)\n",
    "tmp5 = math.log10(len(firstten)/(1 + df['interesting']))\n",
    "print('interesting')\n",
    "print(tmp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtime = defaultdict(int)\n",
    "ofinterest = None\n",
    "for d in data:\n",
    "    if d['reviewID'] == 'r75487422':\n",
    "        ofinterest = d\n",
    "        rt = d['text'].translate(str.maketrans('', '', string.punctuation)).lower().split(' ')\n",
    "        for w in rt:\n",
    "            wordtime[w] += 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF:\n",
      "destiny:\n",
      "3.3010299956639813\n",
      "annoying:\n",
      "3.6712942884311257\n",
      "likeable\n",
      "6.0915149811213505\n",
      "chapter\n",
      "6.644010494967699\n",
      "interesting\n",
      "2.7150709595157574\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF:')\n",
    "tmp1 = tmp1 * wordtime['destiny']\n",
    "print('destiny:')\n",
    "print(tmp1)\n",
    "tmp2 = tmp2 * wordtime['annoying']\n",
    "print('annoying:')\n",
    "print(tmp2)\n",
    "tmp3 = tmp3 * wordtime['likeable']\n",
    "print('likeable')\n",
    "print(tmp3)\n",
    "tmp4 = tmp4 * wordtime['chapter']\n",
    "print('chapter')\n",
    "print(tmp4)\n",
    "tmp5 = tmp5 * wordtime['interesting']\n",
    "print('interesting')\n",
    "print(tmp5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Inverse Document Frequencies:<br>\n",
    "destiny:<br>\n",
    "3.3010299956639813<br>\n",
    "annoying:<br>\n",
    "1.8356471442155629<br>\n",
    "likeable<br>\n",
    "3.0457574905606752<br>\n",
    "chapter<br>\n",
    "2.214670164989233<br>\n",
    "interesting<br>\n",
    "1.3575354797578787<br><br>\n",
    "\n",
    "TF-IDF:<br>\n",
    "destiny:<br>\n",
    "3.3010299956639813<br>\n",
    "annoying:<br>\n",
    "3.6712942884311257<br>\n",
    "likeable<br>\n",
    "6.0915149811213505<br>\n",
    "chapter<br>\n",
    "6.644010494967699<br>\n",
    "interesting<br>\n",
    "2.7150709595157574<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION 5\n",
    "ugrams = [x[1] for x in ugrams[:1000]]\n",
    "gramId = dict(zip(ugrams, range(len(ugrams))))\n",
    "gramSet = set(ugrams)\n",
    "def feature3(datum):\n",
    "    feat = [0]*len(gramSet)\n",
    "    r = datum.split(' ')\n",
    "    currcount = defaultdict(int)\n",
    "    for word in r:\n",
    "        currcount[word] += 1\n",
    "    myset = set([])\n",
    "    for word in r:\n",
    "        if word in gramSet and not word in myset:\n",
    "            myset.add(word)\n",
    "            num = currcount[word]\n",
    "            denom = math.log10(len(firstten)/(1 + df[word]))\n",
    "            feat[gramId[word]] = (num * denom)\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X2 = [feature3(d) for d in firstten]\n",
    "y2 = [res(d) for d in data[0:10000]]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2135836747754345\n"
     ]
    }
   ],
   "source": [
    "est = clf.predict(X2)\n",
    "mse = numpy.square(numpy.subtract(est, y2)).mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "MSE = 4.2135836747754345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 6\n",
    "arr1 = [0] * len(gramSet)\n",
    "text1 = ofinterest['text'].translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "currcount = defaultdict(int)\n",
    "for val in text1:\n",
    "    currcount[val] += 1\n",
    "for val in text1:\n",
    "    if val in gramSet:\n",
    "        p1 = currcount[val]\n",
    "        p2 = math.log10(len(gramSet) / (1 + df[val]))\n",
    "        arr1[gramId[val]] = (p1 * p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r33215456\n"
     ]
    }
   ],
   "source": [
    "mmax = 0\n",
    "rmax = ''\n",
    "for i in range(0, 10000):\n",
    "    arr2 = [0] * len(gramSet)\n",
    "    curr = data[i]['text'].translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "    currcount = defaultdict(int)\n",
    "    for val in curr:\n",
    "        currcount[val] += 1\n",
    "    for val in curr:\n",
    "        if val in gramSet:\n",
    "            p1 = currcount[val]\n",
    "            p2 = math.log10(len(gramSet) / (1 + df[val]))\n",
    "            arr2[gramId[val]] = (p1 * p2)\n",
    "    t1 = sum(i[0] * i[1] for i in zip(arr1, arr2))\n",
    "    t2 = math.sqrt(sum(numpy.array(arr1)**2)) + math.sqrt(sum(numpy.array(arr2)**2))\n",
    "    sim = t1/t2\n",
    "    if sim > mmax:\n",
    "        mmax = sim\n",
    "        rmax = data[i]['reviewID']\n",
    "print(rmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "most similar reviewId: r33215456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 7\n",
    "# train_X.append(data[i]['text'].translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "random.shuffle(data)\n",
    "test_X = []\n",
    "train_X = []\n",
    "valid_X = []\n",
    "test_y = []\n",
    "train_y = []\n",
    "valid_y = []\n",
    "for i in range(0, len(data)):\n",
    "    if i < 10000:\n",
    "        train_y.append(math.log(data[i]['hours'] + 1, 2))\n",
    "        train_X.append(data[i]['text'])\n",
    "    elif i < 20000:\n",
    "        test_y.append(math.log(data[i]['hours'] + 1, 2))\n",
    "        test_X.append(data[i]['text'])\n",
    "    elif i < 30000:\n",
    "        valid_y.append(math.log(data[i]['hours'] + 1, 2))\n",
    "        valid_X.append(data[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigrams, removing punctuation, tfidf scores\n",
    "counts = defaultdict(int)\n",
    "unpdf = defaultdict(int)\n",
    "for l in train_X:\n",
    "    curr = set([])\n",
    "    l = l.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    b = l.split(\" \")\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "        if val not in curr:\n",
    "            curr.add(val)\n",
    "            unpdf[val] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "unp = [x[1] for x in counts[:1000]]\n",
    "unpId = dict(zip(unp, range(len(unp))))\n",
    "unpSet = set(unp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.448111788052944, 6.761583602001666, 6.85650805314973]\n",
      "[4.448111836548716, 6.76097112404808, 6.855889569648352]\n",
      "[4.448116643001447, 6.754887628743253, 6.849747451429933]\n",
      "[4.44855778688827, 6.697890672530793, 6.792289950852203]\n",
      "[4.4720878881908215, 6.349980586845211, 6.44413898123869]\n"
     ]
    }
   ],
   "source": [
    "def feature10(datum):\n",
    "    feat = [0]*len(unpSet)\n",
    "    r = datum.translate(str.maketrans('', '', string.punctuation)).lower().split(' ')\n",
    "    currcount = defaultdict(int)\n",
    "    for word in r:\n",
    "        currcount[word] += 1\n",
    "    myset = set([])\n",
    "    for word in r:\n",
    "        if word in unpSet and not word in myset:\n",
    "            myset.add(word)\n",
    "            p1 = currcount[word]\n",
    "            p2 = math.log10(len(train_X)/(1 + unpdf[word]))\n",
    "            feat[unpId[word]] = (p1 * p2)\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature10(d) for d in train_X]\n",
    "t3 = [feature10(d) for d in test_X]\n",
    "t2 = [feature10(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.448111794891627, 6.761403279373198, 6.856325280901804]\n",
      "[4.448112517466186, 6.759173890482406, 6.854068047784618]\n",
      "[4.448181900249314, 6.737494585242364, 6.8321313363385645]\n",
      "[4.45307728156437, 6.567159742241056, 6.66062495819836]\n",
      "[4.547305386666309, 6.041192110869887, 6.139042048101774]\n"
     ]
    }
   ],
   "source": [
    "# Unigrams, removing punctuation, word counts\n",
    "def feature11(datum):\n",
    "    feat = [0]*len(unpSet)\n",
    "    r = datum.translate(str.maketrans('', '', string.punctuation)).lower().split(' ')\n",
    "    for word in r:\n",
    "        if word in unpSet:\n",
    "            feat[unpId[word]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature11(d) for d in train_X]\n",
    "t3 = [feature11(d) for d in test_X]\n",
    "t2 = [feature11(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigrams, keeping punctuation, tfidf scores\n",
    "counts = defaultdict(int)\n",
    "updf = defaultdict(int)\n",
    "for l in train_X:\n",
    "    b = l.lower().split(\" \")\n",
    "    curr = set([])\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "        if val not in curr:\n",
    "            curr.add(val)\n",
    "            updf[val] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "up = [x[1] for x in counts[:1000]]\n",
    "upId = dict(zip(up, range(len(up))))\n",
    "upSet = set(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.483481799621346, 8.055930993379272, 6.929421781910879]\n",
      "[4.483481854798076, 8.05478999731367, 6.928746967050129]\n",
      "[4.483487320844511, 8.043433187985066, 6.922042850334407]\n",
      "[4.483986836779045, 7.934931964234332, 6.859096456060031]\n",
      "[4.509951965909808, 7.1959706553821325, 6.468977918645232]\n"
     ]
    }
   ],
   "source": [
    "def feature12(datum):\n",
    "    feat = [0]*len(upSet)\n",
    "    r = datum.lower().split(' ')\n",
    "    currcount = defaultdict(int)\n",
    "    for word in r:\n",
    "        currcount[word] += 1\n",
    "    myset = set([])\n",
    "    for word in r:\n",
    "        if word in upSet and not word in myset:\n",
    "            myset.add(word)\n",
    "            p1 = currcount[word]\n",
    "            p2 = math.log10(len(train_X)/(1 + updf[word]))\n",
    "            feat[upId[word]] = (p1 * p2)\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature12(d) for d in train_X]\n",
    "t3 = [feature12(d) for d in test_X]\n",
    "t2 = [feature12(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.483481807767196, 8.055482055923203, 6.9292033575724465]\n",
      "[4.4834826656453775, 8.050309109877, 6.926569584066258]\n",
      "[4.483564826768958, 7.999460653274094, 6.900932228158309]\n",
      "[4.489260782117701, 7.567906247692666, 6.69772907896097]\n",
      "[4.594636508523769, 6.161785145786728, 6.077082820205692]\n"
     ]
    }
   ],
   "source": [
    "# Unigrams, keeping punctuation, word counts\n",
    "def feature13(datum):\n",
    "    feat = [0]*len(upSet)\n",
    "    r = datum.lower().split(' ')\n",
    "    for word in r:\n",
    "        if word in upSet:\n",
    "            feat[upId[word]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature13(d) for d in train_X]\n",
    "t3 = [feature13(d) for d in test_X]\n",
    "t2 = [feature13(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams, removing punctuation, tfidf scores\n",
    "counts = defaultdict(int)\n",
    "bnpdf = defaultdict(int)\n",
    "for l in train_X:\n",
    "    curr = set([])\n",
    "    l = l.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    b = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "        if val not in curr:\n",
    "            curr.add(val)\n",
    "            bnpdf[val] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "bnp = [x[1] for x in counts[:1000]]\n",
    "bnpId = dict(zip(bnp, range(len(bnp))))\n",
    "bnpSet = set(bnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.382084413516019, 5.264208278873948, 5.350977452054177]\n",
      "[5.382084414853578, 5.264204046223508, 5.350975803183231]\n",
      "[5.382084548585164, 5.264161844266324, 5.350959436463311]\n",
      "[5.382097897488407, 5.263752254986487, 5.350807944042781]\n",
      "[5.383408888294626, 5.260875320278863, 5.350486679325185]\n"
     ]
    }
   ],
   "source": [
    "def feature14(datum):\n",
    "    feat = [0]*len(bnpSet)\n",
    "    r = datum.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    r = zip(r.split(\" \")[:-1], r.split(\" \")[1:])\n",
    "    currcount = defaultdict(int)\n",
    "    for word in r:\n",
    "        currcount[word] += 1\n",
    "    myset = set([])\n",
    "    for word in r:\n",
    "        if word in bnpSet and not word in myset:\n",
    "            myset.add(word)\n",
    "            p1 = currcount[word]\n",
    "            p2 = math.log10(len(train_X)/(1 + bnpdf[word]))\n",
    "            feat[bnpId[word]] = (p1 * p2)\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature14(d) for d in train_X]\n",
    "t3 = [feature14(d) for d in test_X]\n",
    "t2 = [feature14(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.576831630473613, 6.73516330313452, 6.520377392365218]\n",
      "[4.576849378370181, 6.730637016758092, 6.515133150076188]\n",
      "[4.577563347221398, 6.692133363632492, 6.47598060761095]\n",
      "[4.591030736205471, 6.4242754638905115, 6.2522368583275005]\n",
      "[4.74948617532988, 5.729936754893262, 5.742410956602475]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams, removing punctuation, word counts\n",
    "def feature15(datum):\n",
    "    feat = [0]*len(bnpSet)\n",
    "    l = datum.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    r = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for w in r:\n",
    "        if w in bnpSet:\n",
    "            feat[bnpId[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature15(d) for d in train_X]\n",
    "t3 = [feature15(d) for d in test_X]\n",
    "t2 = [feature15(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams, keeping punctuation, tfidf scores\n",
    "counts = defaultdict(int)\n",
    "bpdf = defaultdict(int)\n",
    "for l in train_X:\n",
    "    curr = set([])\n",
    "    l = l.lower()\n",
    "    b = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for val in b:\n",
    "        counts[val] += 1\n",
    "        if val not in curr:\n",
    "            curr.add(val)\n",
    "            bpdf[val] += 1\n",
    "counts = [(counts[w], w) for w in counts]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "bp = [x[1] for x in counts[:1000]]\n",
    "bpId = dict(zip(bp, range(len(bp))))\n",
    "bpSet = set(bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.382084413516019, 5.264208278873948, 5.350977452054177]\n",
      "[5.382084414853578, 5.264204046223508, 5.350975803183231]\n",
      "[5.382084548585164, 5.264161844266324, 5.350959436463311]\n",
      "[5.382097897488407, 5.263752254986487, 5.350807944042781]\n",
      "[5.383408888294626, 5.260875320278863, 5.350486679325185]\n"
     ]
    }
   ],
   "source": [
    "def feature16(datum):\n",
    "    feat = [0]*len(bpSet)\n",
    "    r = datum.lower()\n",
    "    r = zip(r.split(\" \")[:-1], r.split(\" \")[1:])\n",
    "    currcount = defaultdict(int)\n",
    "    for word in r:\n",
    "        currcount[word] += 1\n",
    "    myset = set([])\n",
    "    for word in r:\n",
    "        if word in bpSet and not word in myset:\n",
    "            myset.add(word)\n",
    "            p1 = currcount[word]\n",
    "            p2 = math.log10(len(train_X)/(1 + bpdf[word]))\n",
    "            feat[bpId[word]] = (p1 * p2)\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature16(d) for d in train_X]\n",
    "t3 = [feature16(d) for d in test_X]\n",
    "t2 = [feature16(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.61928318160182, 6.396641142375481, 6.450978816279689]\n",
      "[4.619297123874244, 6.3919217294605835, 6.446146919080924]\n",
      "[4.620013766561267, 6.352872293303977, 6.407180943004867]\n",
      "[4.635516874738719, 6.1220628734252776, 6.1798517883637105]\n",
      "[4.800472344835454, 5.622612489935406, 5.693520746413202]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams, keeping punctuation, word counts\n",
    "def feature17(datum):\n",
    "    feat = [0]*len(bpSet)\n",
    "    l = datum.lower()\n",
    "    r = zip(l.split(\" \")[:-1], l.split(\" \")[1:])\n",
    "    for w in r:\n",
    "        if w in bpSet:\n",
    "            feat[bpId[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "    \n",
    "X = [feature17(d) for d in train_X]\n",
    "t3 = [feature17(d) for d in test_X]\n",
    "t2 = [feature17(d) for d in valid_X]\n",
    "\n",
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c1.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c1.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(0.1, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c2.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c2.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c3.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c3.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c4.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c4.append(mse)\n",
    "\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X, train_y)\n",
    "pred = clf.predict(X)\n",
    "mse = numpy.square(numpy.subtract(pred, train_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t2)\n",
    "mse = numpy.square(numpy.subtract(pred, test_y)).mean()\n",
    "c5.append(mse)\n",
    "pred = clf.predict(t3)\n",
    "mse = numpy.square(numpy.subtract(pred, valid_y)).mean()\n",
    "c5.append(mse)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)\n",
    "print(c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Format is [training MSE, validation MSE, testing MSE]<br>\n",
    "Model MSEs are listed in order of C = 0.01, 0.1, 1.0, 10.0, 100.0<br><br>\n",
    "Unigrams, removing punctuation, tfidf scores<br>\n",
    "[4.448111788052944, 6.761583602001666, 6.85650805314973]<br>\n",
    "[4.448111836548716, 6.76097112404808, 6.855889569648352]<br>\n",
    "[4.448116643001447, 6.754887628743253, 6.849747451429933]<br>\n",
    "[4.44855778688827, 6.697890672530793, 6.792289950852203]<br>\n",
    "[4.4720878881908215, 6.349980586845211, 6.44413898123869]<br><br>\n",
    "\n",
    "Unigrams, removing punctuation, word counts<br>\n",
    "[4.448111794891627, 6.761403279373198, 6.856325280901804]<br>\n",
    "[4.448112517466186, 6.759173890482406, 6.854068047784618]<br>\n",
    "[4.448181900249314, 6.737494585242364, 6.8321313363385645]<br>\n",
    "[4.45307728156437, 6.567159742241056, 6.66062495819836]<br>\n",
    "[4.547305386666309, 6.041192110869887, 6.139042048101774]<br><br>\n",
    "\n",
    "Unigrams, keeping punctuation, tfidf scores<br>\n",
    "[4.483481799621346, 8.055930993379272, 6.929421781910879]<br>\n",
    "[4.483481854798076, 8.05478999731367, 6.928746967050129]<br>\n",
    "[4.483487320844511, 8.043433187985066, 6.922042850334407]<br>\n",
    "[4.483986836779045, 7.934931964234332, 6.859096456060031]<br>\n",
    "[4.509951965909808, 7.1959706553821325, 6.468977918645232]<br><br>\n",
    "\n",
    "Unigrams, keeping punctuation, word counts<br>\n",
    "[4.483481807767196, 8.055482055923203, 6.9292033575724465]<br>\n",
    "[4.4834826656453775, 8.050309109877, 6.926569584066258]<br>\n",
    "[4.483564826768958, 7.999460653274094, 6.900932228158309]<br>\n",
    "[4.489260782117701, 7.567906247692666, 6.69772907896097]<br>\n",
    "[4.594636508523769, 6.161785145786728, 6.077082820205692]<br><br>\n",
    "\n",
    "Bigrams, removing punctuation, tfidf scores<br>\n",
    "[5.382084413516019, 5.264208278873948, 5.350977452054177]<br>\n",
    "[5.382084414853578, 5.264204046223508, 5.350975803183231]<br>\n",
    "[5.382084548585164, 5.264161844266324, 5.350959436463311]<br>\n",
    "[5.382097897488407, 5.263752254986487, 5.350807944042781]<br>\n",
    "[5.383408888294626, 5.260875320278863, 5.350486679325185]<br><br>\n",
    "\n",
    "Bigrams, removing punctuation, word counts<br>\n",
    "[4.576831630473613, 6.73516330313452, 6.520377392365218]<br>\n",
    "[4.576849378370181, 6.730637016758092, 6.515133150076188]<br>\n",
    "[4.577563347221398, 6.692133363632492, 6.47598060761095]<br>\n",
    "[4.591030736205471, 6.4242754638905115, 6.2522368583275005]<br>\n",
    "[4.74948617532988, 5.729936754893262, 5.742410956602475]<br><br>\n",
    "\n",
    "Bigrams, keeping punctuation, tfidf scores<br>\n",
    "[5.382084413516019, 5.264208278873948, 5.350977452054177]<br>\n",
    "[5.382084414853578, 5.264204046223508, 5.350975803183231]<br>\n",
    "[5.382084548585164, 5.264161844266324, 5.350959436463311]<br>\n",
    "[5.382097897488407, 5.263752254986487, 5.350807944042781]<br>\n",
    "[5.383408888294626, 5.260875320278863, 5.350486679325185]<br><br>\n",
    "\n",
    "Bigrams, keeping punctuation, word counts<br>\n",
    "[4.61928318160182, 6.396641142375481, 6.450978816279689]<br>\n",
    "[4.619297123874244, 6.3919217294605835, 6.446146919080924]<br>\n",
    "[4.620013766561267, 6.352872293303977, 6.407180943004867]<br>\n",
    "[4.635516874738719, 6.1220628734252776, 6.1798517883637105]<br>\n",
    "[4.800472344835454, 5.622612489935406, 5.693520746413202]<br><br>\n",
    "\n",
    "Best validation set performance is bigrams, tfidf scores, (removing puncutation or keeping punctuation), and C = 100. The validation MSE is 5.260875320278863 and the test MSE is 5.350486679325185 for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
